{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc90aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming utility.py is in the same directory\n",
    "from utility import import_txt_file, import_csv_file, import_excel_file, import_pickle_file, import_json_file, import_html_file, import_sqlite_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba34898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TXT File - Rows: 7756, Columns: 21\n",
      "4th record from the end: ['1414271365_EuFmeZ+vsDuryP8F', '3abcb63cbef3c7a5d77e7b7b5da0dacf', '4', 'Mozilla/5.0 (iPad; CPU OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) GSA/5.1.42378 Mobile/11D257 Safari/9537.53', 'iPad - Web', '2015-01-11', '2015-01-11 03:09:42', '2015-01-11 03:23:26', '1', '0', '0', 'bba9bb8e12360e95a664e2f7c46124bc', '5', 'Mozilla/5.0 (iPad; CPU OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) GSA/5.2.43972 Mobile/11D257 Safari/9537.53', 'iPad - Web', '2015-02-16', '2015-02-16 02:48:38', '2015-02-16 02:59:20', '1', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "txt_data = import_txt_file('/Users/hritvikmahajan/Downloads/ALY6140/data/network_data.txt')\n",
    "# Splitting lines and extracting header and records\n",
    "lines = txt_data.split('\\n')\n",
    "# Filtering out empty lines\n",
    "non_empty_lines = [line for line in lines if line.strip()]\n",
    "header = non_empty_lines[0].split('|')\n",
    "records = [line.split('|') for line in non_empty_lines[1:]]\n",
    "\n",
    "# Displaying information\n",
    "txt_rows, txt_columns = len(records), len(header)\n",
    "print(f'TXT File - Rows: {txt_rows}, Columns: {txt_columns}')\n",
    "print('4th record from the end:', records[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b262d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File - Rows: 1244, Columns: 22\n",
      "10th record: ['0.102642779', '0.056275275', '0.038681619', '0.135835811', '0.040680554', '0.043731848', '0.033648687', '0.080094268', '0.035135646', '0.079896238', '0.035080492', '0.033813994', '0.02980087', '0.033813994', '0.02980087', '0.005415946', '0.001867978', '0.027369265', '0.001969187', '0.10361257', '0.036480505', '10']\n"
     ]
    }
   ],
   "source": [
    "# For csv file\n",
    "csv_data = import_csv_file('/Users/hritvikmahajan/Downloads/ALY6140/data/Neural_data.csv')\n",
    "\n",
    "# Exclude header from row count\n",
    "csv_rows = len(csv_data) - 1  # Subtracting 1 to exclude the header\n",
    "csv_columns = len(csv_data[0])\n",
    "print(f'CSV File - Rows: {csv_rows}, Columns: {csv_columns}')\n",
    "\n",
    "# Display the 10th record (excluding header)\n",
    "print('10th record:', csv_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83d6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel File - Rows: 700, Columns: 16\n",
      "6th record:\n",
      "Segment                         Government\n",
      "Country                            Germany\n",
      "Product                          Carretera\n",
      "Discount Band                         None\n",
      "Units Sold                          1513.0\n",
      "Manufacturing Price                      3\n",
      "Sale Price                             350\n",
      "Gross Sales                       529550.0\n",
      "Discounts                              0.0\n",
      " Sales                            529550.0\n",
      "COGS                              393380.0\n",
      "Profit                            136170.0\n",
      "Date                   2014-12-01 00:00:00\n",
      "Month Number                            12\n",
      "Month Name                        December\n",
      "Year                                  2014\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# For excel file\n",
    "excel_data = import_excel_file('/Users/hritvikmahajan/Downloads/ALY6140/data/Excel_report.xlsx', sheet_name='Sheet000', header=3, usecols=lambda x: x not in [0, 1, 2])\n",
    "\n",
    "# Exclude empty rows and columns from row and column count\n",
    "non_empty_rows = excel_data.dropna(how='all')\n",
    "non_empty_columns = non_empty_rows.dropna(axis=1, how='all')\n",
    "\n",
    "# Exclude unnamed columns\n",
    "non_empty_columns = non_empty_columns.loc[:, ~non_empty_columns.columns.str.contains('^Unnamed')]\n",
    "\n",
    "excel_rows, excel_columns = non_empty_columns.shape\n",
    "print(f'Excel File - Rows: {excel_rows}, Columns: {excel_columns}')\n",
    "\n",
    "# Display the 6th record (excluding empty rows, unnamed columns)\n",
    "print('6th record:')\n",
    "print(non_empty_columns.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a4e8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 5),\n",
       " sepal_length          6.7\n",
       " sepal_width           3.1\n",
       " petal_length          5.6\n",
       " petal_width           2.4\n",
       " species         virginica\n",
       " Name: 140, dtype: object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with pickle file\n",
    "pickle_file_path = '/Users/hritvikmahajan/Downloads/ALY6140/data/iris_data.pkl'\n",
    "pickle_data = import_pickle_file(pickle_file_path)\n",
    "\n",
    "# Show the shape (number of rows and columns)\n",
    "shape_pickle = pickle_data.shape\n",
    "\n",
    "# Show the 10th record from the end\n",
    "tenth_record_from_end_pickle = pickle_data.iloc[-10]  # Note: 0-based indexing\n",
    "\n",
    "shape_pickle, tenth_record_from_end_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f8304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Test with html file\n",
    "html_file_path = '/Users/hritvikmahajan/Downloads/ALY6140/data/grativational_wave.html'\n",
    "html_content = import_html_file(html_file_path)\n",
    "\n",
    "# Parse HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the number of <img> tags\n",
    "num_img_tags = len(soup.find_all('img'))\n",
    "\n",
    "# Find the number of images with the file extension .png in the 'grativational_wave_files' folder\n",
    "png_folder_path = '/Users/hritvikmahajan/Downloads/ALY6140/data/grativational_wave_files'\n",
    "\n",
    "# Extract image file names ending with '.png' from the <img> tags\n",
    "png_images = [os.path.basename(img['src']) for img in soup.find_all('img') if img['src'].lower().endswith('.png')]\n",
    "\n",
    "# Filter out images that don't exist in the folder\n",
    "existing_png_images = [image for image in png_images if os.path.isfile(os.path.join(png_folder_path, image))]\n",
    "\n",
    "num_img_tags, len(existing_png_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3877c5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 12),\n",
       " Index(['mass', 'year', 'reclat', 'reclong', 'geolocation',\n",
       "        ':@computed_region_cbhk_fwbd', ':@computed_region_nnqa_25f4'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Test with json file\n",
    "json_file_path = '/Users/hritvikmahajan/Downloads/ALY6140/data/nested_data.json'\n",
    "json_data = import_json_file(json_file_path)\n",
    "\n",
    "# Convert JSON data to Pandas DataFrame\n",
    "json_df = pd.DataFrame(json_data)\n",
    "\n",
    "# Find the shape of the DataFrame\n",
    "data_shape = json_df.shape\n",
    "\n",
    "# Find columns with null values\n",
    "null_columns = json_df.columns[json_df.isnull().any()]\n",
    "\n",
    "data_shape, null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c502e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Germany', 156.48)], [('Chile', 6.659999999999999)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with SQLite database file\n",
    "sqlite_db_file_path = '/Users/hritvikmahajan/Downloads/ALY6140/data/chinook.db'\n",
    "query_a = '''\n",
    "    SELECT BillingCountry, SUM(Total) AS TotalSpending\n",
    "    FROM invoices\n",
    "    GROUP BY BillingCountry\n",
    "    ORDER BY TotalSpending DESC\n",
    "    LIMIT 1 OFFSET 4;\n",
    "'''\n",
    "\n",
    "query_b = '''\n",
    "    SELECT BillingCountry, AVG(Total) AS AvgSpendingPerCustomer\n",
    "    FROM invoices\n",
    "    GROUP BY BillingCountry\n",
    "    ORDER BY AvgSpendingPerCustomer DESC\n",
    "    LIMIT 1;\n",
    "'''\n",
    "\n",
    "# Execute queries\n",
    "result_a = import_sqlite_database(sqlite_db_file_path, query_a)\n",
    "result_b = import_sqlite_database(sqlite_db_file_path, query_b)\n",
    "\n",
    "result_a, result_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
